---
title: "Ordinal regression models to analyze Likert scale data"
author: gabriela
categories: [ tutorial ]
image: assets/images/2022-10-28-ordinal/unnamed-chunk-10-1.png
featured: false
output:
  html_document: default
  pdf_document: default
  md_document:
    variant: gfm
    preserve_yaml: TRUE
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_knit$set(base.dir="../../", base.url="/")
knitr::opts_chunk$set(fig.path="assets/images/2022-10-28-ordinal/", dpi = 600,
                      cache.path = 'cache/', cache=TRUE, dev.args=list(png=list(type="cairo")),
                      fig.align='center', message=FALSE, warning=FALSE, echo=TRUE, results='hold')
```


Today I am going to present on an alternative way to analyze Likert scale data by using ordinal regression instead of linear regression. But first, why is it even a problem to use linear regression when analyzing these data?

Here is the thing: in our research, we frequently use Likert scales to get ratings of how participants perceive/evaluate/feel certain features. After collecting the data, we calculate the mean and sd of the items in our scales. However, when doing this we don't take into account that steps along a Likert scale may not be equivalent in terms of magnitude.

Basically, Likert scales are ordinal scales that offer a way of categorizing the feature measured in a direction (i.e. 1\<2\<3\<4\<5...), but do not assume that the magnitude between each step is equal (as opposed to continuous variables). Anyways, when analyzing the data using linear models, we treat an ordinal variable as if it was a continuous one, without accounting for the variance that may result from the fact that the steps in the scale are not equidistant.

My queries about this problem of the Likert scales came from my research trying to get ratings of the severity of wrongdoings when participants were recalling a harm. In a 7-point Likert scale where *1 = notÂ severe at all; and 7 = extremely severe,* I can say that my friend lying to me about having an affair with my boss is a 4, and other person can say that their partner lying to them about his plans for the weekend is a 5. This does not necessarily mean that the latter is 25% worse than the former. It just means that one of the harms seems to be more severe than the other.

![](../assets/images/2022-10-28-ordinal/likert.png)

All this to say that it would be useful to find a way to analyze Likert scale data accounting for differences in the magnitudes within the thresholds of the scales. And here is the answer: Ordinal logistic regressions! So first, we will run the following packages:

```{r}
library(tidyverse)
library(brms)
library(tidybayes)
library(distributional)

memfor_data_s5 <- read_csv('forgiveness_data.csv')
```

Just to have a reference, we will first do a regular linear regression:

```{r}
m.gaussian <- brm(severity_action ~ 1, data=memfor_data_s5)
summary(m.gaussian)

ggplot(memfor_data_s5, aes(x=severity_action)) +
  geom_histogram(aes(y=stat(density)), binwidth=1) +
  geom_line(aes(x=.value, y=y), data=tibble(.value=seq(1, 7, .01)) %>% 
              mutate(y=dnorm(.value, mean=mean(memfor_data_s5$severity_action),
                             sd=sd(memfor_data_s5$severity_action)))) +
  theme_classic()
```

We get a mean of 4.59 and a sigma of 1.63. In the plot, you can see that even though the probability of getting ratings of 5 is higher than the probability of getting ratings of 4, that is not accounted for in the linear model.

Now, we are going to use an ordinal regression. In this case, we will use the function brm (Fit Bayesian generalized (non-)linear multivariate multilevel models) from the brms package.

```{r}
m <- brm(severity_action ~ 1, data=memfor_data_s5, family=cumulative(link='probit'), cores=4)
summary(m)

intercept_draws <- m %>%
  gather_draws(b_Intercept[index]) %>%
  median_hdi
```

Notice that in this case, we have six thresholds that result in the 7 points of the Likert scale. The model gives and estimate of the value of the threshold and also confidence intervals that account for the uncertainty. Cool!

When we plot this, we are able to see the six thresholds with the values that were modeled from our data. You can see that the distance between the thresholds varies (as opposed to what we would assume when using a linear model). In this particular case, the distance between the thresholds are not **very** different, but we can see a shorter distance between the third (-0.57) and the fourth threshold (-0.29).

```{r}
ggplot(intercept_draws, aes(x=.value)) +
  geom_line(aes(y=y), data=tibble(.value=seq(-3, 3, .01)) %>% mutate(y=dnorm(.value))) +
  geom_vline(aes(xintercept=.value)) +
  xlim(-3, 3) +
  theme_classic()
```

This just means that the probability of falling between different thresholds varies. In our case, it seems as if the probability of falling between the third and fourth threshold is lower than the probability of falling between the fourth and fifth threshold. This makes sense if we look back to the histogram of the linear regression that shows the probability of ratings of 5 (corresponds to the fourth and fifth threshold) seems to be higher that the probability of ratings of 4 (corresponds to the third and fourth threshold).

So now, let's find those probabilities! For this, we have to create some fake kind of 'group' that in this case is X=1 (yes?)

```{r}
probabilities <- m %>%
  epred_draws(newdata=tibble(X=1)) %>%
  group_by(.draw) %>%
  mutate(.category=as.numeric(.category))
```

Now, lets plot our new ordinal model and see how it looks!

```{r}
ggplot(memfor_data_s5, aes(x=severity_action)) +
  geom_histogram(aes(y=stat(density)), color='black', fill=NA, binwidth=1) +
  stat_ccdfinterval(aes(x=.category, y=.epred, 
                    slab_alpha = stat(f)), thickness = 1,
                    show.legend=FALSE, data=probabilities) +
  ylab('Probability') + xlab('Severity of Action') +
  theme_classic()
```

In this plot, you will see the data and the model, the probability for each point and, more interestingly, that the model accounts for the uncertainty and gives us confidence intervals. Nice!

But well, the idea would be to get to a point in which we find something that corresponds to the mean for a continuous variable. And to get that, what we need to do is to sum up the product of the probabilities by the category to which they belong (is this right?)

```{r}
draws_mean <- probabilities %>%
  summarize(mean=sum(.category * .epred))

draws_mean %>%
  median_hdi(mean)
```

And there you go! We have a 'mean' resulting from the ordinal regression that is useful for our research purposes. However, you could have noticed that the mean that we got with the ordinal regression (4.59) is exactly the same that we found when we did the good old linear regression. So, why should we get through all the trouble? Well, apparently this is not always the case always, and sometimes the values that you find differ, particularly when the thresholds are less equidistant. In those cases, the ordinal regression is the way to go since it actually accounts for this.

So, in our previous example we actually didn't have predictors that could account for the distribution of our data. Now, lets try to model the same data, but with predictors.

This data is part of my research on memory and forgiveness. For this study we asked participants to rate the severity of the harm committed by another person, and if the have or have not forgiven the wrongdoer. We would expect participants who didn't forgave the wrongdoers to have higher ratings for the severity of the wrongdoing. Let's see if that was the case.

First, lets see again how the gaussian model would look like:

```{r}
m.gaussian_for <- brm(severity_action ~ condition, data=memfor_data_s5)
summary(m.gaussian)

ggplot(memfor_data_s5, aes(x=severity_action)) +
  geom_histogram(aes(y=stat(density)), binwidth=1) +
  geom_line(aes(x=.value, y=y), data=tibble(.value=seq(1, 7, .01)) %>% 
              mutate(y=dnorm(.value, mean=mean(memfor_data_s5$severity_action),
                             sd=sd(memfor_data_s5$severity_action)))) +
  ylab('Probability') + xlab('Severity of Action') +
  facet_grid(condition ~ .) +
  theme_classic()
```

Now, let's try with the ordinal regression

```{r}
m_for <- brm(severity_action ~ condition, data=memfor_data_s5, family=cumulative(link='probit'), cores=4)
summary(m_for)

intercept_draws <- m_for %>%
  gather_draws(b_Intercept[index]) %>%
  median_hdi
```

Now, let's take a look at how the distribution looks when we include forgiveness as a condition

```{r}
ggplot(intercept_draws, aes(x=.value)) +
  geom_area(aes(y=y), fill='red', alpha=.5, data=tibble(.value=seq(-3, 3, .01)) %>% mutate(y=dnorm(.value))) +
  geom_area(aes(y=y), fill='blue', alpha=.5, data=tibble(.value=seq(-3, 3, .01)) %>% mutate(y=dnorm(.value, mean=0.54))) +
  geom_vline(aes(xintercept=.value)) +
  xlim(-3, 3) +
  theme_classic()
```

Now let's find the probabilities by condition

```{r}
probabilities_for <- m_for %>%
  epred_draws(newdata=tibble(condition=unique(memfor_data_s5$condition))) %>%
  group_by(condition, .draw) %>%
  mutate(.category=as.numeric(.category))
```

And now, this is how our ordinal regression looks like:

```{r}
ggplot(memfor_data_s5, aes(x=severity_action)) +
  geom_histogram(aes(y=stat(density)), color='black', fill=NA, binwidth=1) +
  stat_ccdfinterval(aes(x=.category, y=.epred, 
                        slab_alpha = stat(f)), thickness = 1,
                    show.legend=FALSE, data=probabilities_for) +
  facet_grid(condition ~ .) +
  ylab('Probability') + xlab('Severity of Action') +
  theme_classic()
```

And here are our means by condition!

```{r}
draws_mean_for <- probabilities_for %>%
  summarize(mean=sum(.category * .epred))

draws_mean_for %>%
  median_hdi(mean)
```
